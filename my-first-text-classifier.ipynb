{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a762c75a",
   "metadata": {},
   "source": [
    "# Text Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6148987",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "7051b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import imblearn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, mean_squared_error, r2_score, multilabel_confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723e742",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa3025b",
   "metadata": {},
   "source": [
    "### Retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "53c36b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>623495513</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>Mon Dec 01 19:30:03 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\nnot_relevant</td>\n",
       "      <td>#AAPL:The 10 best Steve Jobs emails ever...htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>623495514</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>Mon Dec 01 19:43:51 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\n1</td>\n",
       "      <td>RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>623495515</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Mon Dec 01 19:50:28 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3</td>\n",
       "      <td>My cat only chews @apple cords. Such an #Apple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>623495516</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>Mon Dec 01 20:26:34 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\n1</td>\n",
       "      <td>I agree with @jimcramer that the #IndividualIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>623495517</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 12:14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>Mon Dec 01 20:29:33 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nobody expects the Spanish Inquisition #AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  623495513     True      golden                  10               NaN   \n",
       "1  623495514     True      golden                  12               NaN   \n",
       "2  623495515     True      golden                  10               NaN   \n",
       "3  623495516     True      golden                  17               NaN   \n",
       "4  623495517    False   finalized                   3    12/12/14 12:14   \n",
       "\n",
       "   sentiment  sentiment:confidence                            date  \\\n",
       "0          3                0.6264  Mon Dec 01 19:30:03 +0000 2014   \n",
       "1          3                0.8129  Mon Dec 01 19:43:51 +0000 2014   \n",
       "2          3                1.0000  Mon Dec 01 19:50:28 +0000 2014   \n",
       "3          3                0.5848  Mon Dec 01 20:26:34 +0000 2014   \n",
       "4          3                0.6474  Mon Dec 01 20:29:33 +0000 2014   \n",
       "\n",
       "             id            query   sentiment_gold  \\\n",
       "0  5.400000e+17  #AAPL OR @Apple  3\\nnot_relevant   \n",
       "1  5.400000e+17  #AAPL OR @Apple             3\\n1   \n",
       "2  5.400000e+17  #AAPL OR @Apple                3   \n",
       "3  5.400000e+17  #AAPL OR @Apple             3\\n1   \n",
       "4  5.400000e+17  #AAPL OR @Apple              NaN   \n",
       "\n",
       "                                                text  \n",
       "0  #AAPL:The 10 best Steve Jobs emails ever...htt...  \n",
       "1  RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...  \n",
       "2  My cat only chews @apple cords. Such an #Apple...  \n",
       "3  I agree with @jimcramer that the #IndividualIn...  \n",
       "4       Nobody expects the Spanish Inquisition #AAPL  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://query.data.world/s/ucw6adw4twegolswpwcjwipvlke2y6?dws=00000', encoding = \"ISO-8859-1\")\n",
    "data = data[data['sentiment'] != 'not_relevant']\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data[\"sentiment\"] = pd.to_numeric(data[\"sentiment\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "6e617733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "3    2162\n",
       "1    1219\n",
       "5     423\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "7d52a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text'].copy()\n",
    "y = data['sentiment'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dede24",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "3047572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b65419d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class: [   0  970    0 1717    0  356]\n",
      "Samples per class: [  0 249   0 445   0  67]\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples per class: {}\".format(np.bincount(y_train)))\n",
    "print(\"Samples per class: {}\".format(np.bincount(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19873d0",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345e3b5c",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "965ece66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {3: 1, 1: 2, 5: 10}\n",
    "\n",
    "pipeLR = Pipeline([('tfidf', TfidfVectorizer()),( 'clf', LogisticRegression())])\n",
    "pipeNB = Pipeline([('tfidf', TfidfVectorizer()),( 'clf', MultinomialNB())])\n",
    "pipeRF = Pipeline([('tfidf', TfidfVectorizer()),( 'clf', RandomForestClassifier())])\n",
    "pipeSVC = Pipeline([('tfidf', TfidfVectorizer()),( 'clf', LinearSVC(class_weight=class_weights, dual=False))])\n",
    "\n",
    "#from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#pipelines with preprocessing smote\n",
    "#pipeLR = ImbPipeline([('tfidf', TfidfVectorizer()), ('sampler', RandomOverSampler(sampling_strategy=\"not majority\")), ('clf', LogisticRegression())])\n",
    "#pipeNB = ImbPipeline([('tfidf', TfidfVectorizer()), ('sampler', RandomOverSampler(sampling_strategy=\"not majority\")), ('clf', MultinomialNB())])\n",
    "#pipeRF = ImbPipeline([('tfidf', TfidfVectorizer()), ('sampler', RandomOverSampler(sampling_strategy=\"not majority\")), ('clf', RandomForestClassifier())])\n",
    "#pipeSVC = ImbPipeline([('tfidf', TfidfVectorizer()), ('sampler', RandomOverSampler(sampling_strategy=\"not majority\")),( 'clf', LinearSVC(class_weight=class_weights, dual=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d2893",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "5aea0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeLR.fit(X_train, y_train)\n",
    "predict_test_LR = pipeLR.predict(X_test)\n",
    "\n",
    "pipeNB.fit(X_train, y_train)\n",
    "predict_test_NB = pipeNB.predict(X_test)\n",
    "\n",
    "pipeRF.fit(X_train, y_train)\n",
    "predict_test_RF = pipeRF.predict(X_test)\n",
    "\n",
    "pipeSVC.fit(X_train, y_train)\n",
    "predict_test_SVC = pipeSVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39033b13",
   "metadata": {},
   "source": [
    "### Testing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "848d34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_test_accuracy = accuracy_score(y_test, predict_test_LR)\n",
    "lr_test_precision = precision_score(y_test, predict_test_LR,average='macro', labels=np.unique(predict_test_LR))\n",
    "lr_test_mse = mean_squared_error(y_test, predict_test_LR)\n",
    "lr_test_rmse = np.sqrt(lr_test_mse)\n",
    "lr_test_r2 = r2_score(y_test, predict_test_LR)\n",
    "\n",
    "nb_test_accuracy = accuracy_score(y_test, predict_test_NB)\n",
    "nb_test_precision = precision_score(y_test, predict_test_NB,average='macro', labels=np.unique(predict_test_NB))\n",
    "nb_test_mse = mean_squared_error(y_test, predict_test_NB)\n",
    "nb_test_rmse = np.sqrt(nb_test_mse)\n",
    "nb_test_r2 = r2_score(y_test, predict_test_NB)\n",
    "\n",
    "rf_test_accuracy = accuracy_score(y_test, predict_test_RF)\n",
    "rf_test_precision = precision_score(y_test, predict_test_RF,average='macro', labels=np.unique(predict_test_RF))\n",
    "rf_test_mse = mean_squared_error(y_test, predict_test_RF)\n",
    "rf_test_rmse = np.sqrt(rf_test_mse)\n",
    "rf_test_r2 = r2_score(y_test, predict_test_RF)\n",
    "\n",
    "svc_test_accuracy = accuracy_score(y_test, predict_test_SVC)\n",
    "svc_test_precision = precision_score(y_test, predict_test_SVC,average='macro', labels=np.unique(predict_test_SVC))\n",
    "svc_test_mse = mean_squared_error(y_test, predict_test_SVC)\n",
    "svc_test_rmse = np.sqrt(svc_test_mse)\n",
    "svc_test_r2 = r2_score(y_test, predict_test_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d294e2",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83954778",
   "metadata": {},
   "source": [
    "## Comparing results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd889338",
   "metadata": {},
   "source": [
    "### Testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "b8a9aea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear regression</td>\n",
       "      <td>0.759527</td>\n",
       "      <td>0.763285</td>\n",
       "      <td>1.135348</td>\n",
       "      <td>1.065527</td>\n",
       "      <td>0.207261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.755585</td>\n",
       "      <td>0.770451</td>\n",
       "      <td>1.151117</td>\n",
       "      <td>1.072901</td>\n",
       "      <td>0.196251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.760841</td>\n",
       "      <td>0.751236</td>\n",
       "      <td>1.240473</td>\n",
       "      <td>1.113765</td>\n",
       "      <td>0.133859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.750329</td>\n",
       "      <td>0.668733</td>\n",
       "      <td>1.219448</td>\n",
       "      <td>1.104286</td>\n",
       "      <td>0.14854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Method  Accuracy Precision       MSE      RMSE        R2\n",
       "0  Linear regression  0.759527  0.763285  1.135348  1.065527  0.207261\n",
       "0        Naive Bayes  0.755585  0.770451  1.151117  1.072901  0.196251\n",
       "0      Random Forest  0.760841  0.751236  1.240473  1.113765  0.133859\n",
       "0                SVC  0.750329  0.668733  1.219448  1.104286   0.14854"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_results = pd.DataFrame(['Linear regression', lr_test_accuracy, lr_test_precision, lr_test_mse, lr_test_rmse, lr_test_r2]).transpose()\n",
    "nb_results = pd.DataFrame(['Naive Bayes', nb_test_accuracy, nb_test_precision, nb_test_mse, nb_test_rmse, nb_test_r2]).transpose()\n",
    "rf_results = pd.DataFrame(['Random Forest', rf_test_accuracy, rf_test_precision, rf_test_mse, rf_test_rmse, rf_test_r2]).transpose()\n",
    "svc_results = pd.DataFrame(['SVC', svc_test_accuracy, svc_test_precision, svc_test_mse, svc_test_rmse, svc_test_r2]).transpose()\n",
    "\n",
    "models_results = pd.concat([lr_results, nb_results, rf_results, svc_results], axis=0)\n",
    "models_results.columns = ['Method', 'Accuracy', 'Precision', 'MSE', 'RMSE', 'R2']\n",
    "models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e343033",
   "metadata": {},
   "source": [
    "### Confusion  matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "68ae77cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR-confusion-matrix:\n",
      " accuracy_score:\n",
      " [[[444  68]\n",
      "  [ 73 176]]\n",
      "\n",
      " [[206 110]\n",
      "  [ 62 383]]\n",
      "\n",
      " [[689   5]\n",
      "  [ 48  19]]]\n",
      " \n",
      "NB-confusion-matrix:\n",
      " accuracy_score:\n",
      " [[[457  55]\n",
      "  [ 78 171]]\n",
      "\n",
      " [[186 130]\n",
      "  [ 45 400]]\n",
      "\n",
      " [[693   1]\n",
      "  [ 63   4]]]\n",
      " \n",
      "RF-confusion-matrix:\n",
      " accuracy_score:\n",
      " [[[435  77]\n",
      "  [ 69 180]]\n",
      "\n",
      " [[217  99]\n",
      "  [ 65 380]]\n",
      "\n",
      " [[688   6]\n",
      "  [ 48  19]]]\n",
      " \n",
      "SVC-confusion-matrix:\n",
      " accuracy_score:\n",
      " [[[445  67]\n",
      "  [ 66 183]]\n",
      "\n",
      " [[229  87]\n",
      "  [ 89 356]]\n",
      "\n",
      " [[658  36]\n",
      "  [ 35  32]]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(f\"LR-confusion-matrix:\\n accuracy_score:\\n {multilabel_confusion_matrix(y_test, predict_test_LR)}\\n \")\n",
    "print(f\"NB-confusion-matrix:\\n accuracy_score:\\n {multilabel_confusion_matrix(y_test, predict_test_NB)}\\n \")\n",
    "print(f\"RF-confusion-matrix:\\n accuracy_score:\\n {multilabel_confusion_matrix(y_test, predict_test_RF)}\\n \")\n",
    "print(f\"SVC-confusion-matrix:\\n accuracy_score:\\n {multilabel_confusion_matrix(y_test, predict_test_SVC)}\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803a40a-0e75-4578-9cc1-5ad9242ee9a8",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "01f00d03-1bfc-4e9b-9f74-0a9e05ef855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: review \"I hate this!\" is negative\n",
      "Linear Regression: review \"Not bad, but I wish there was more.\" is negative\n",
      "Linear Regression: review \"Latest news regarding the stock market.\" is neutral\n",
      "Linear Regression: review \"I used to love it but no more...\" is negative\n",
      "Linear Regression: review \"Great! Wonderful!\" is positive\n"
     ]
    }
   ],
   "source": [
    "sentiment_mapping = { 1: \"negative\", 3: \"neutral\", 5: \"positive\"}\n",
    "\n",
    "review1 = \"I hate this!\"\n",
    "review2 = \"Not bad, but I wish there was more.\"\n",
    "review3 = \"Latest news regarding the stock market.\"\n",
    "review4 = \"I used to love it but no more...\"\n",
    "review5 = \"Great! Wonderful!\"\n",
    "\n",
    "prediction_LR_r1 = pipeLR.predict([review1])\n",
    "prediction_LR_r2 = pipeLR.predict([review2])\n",
    "prediction_LR_r3 = pipeLR.predict([review3])\n",
    "prediction_LR_r4 = pipeLR.predict([review4])\n",
    "prediction_LR_r5 = pipeLR.predict([review5])\n",
    "\n",
    "\n",
    "sent_label_LR_r1 = sentiment_mapping.get(prediction_LR_r1[0], \"unknown\")\n",
    "sent_label_LR_r2 = sentiment_mapping.get(prediction_LR_r2[0], \"unknown\")\n",
    "sent_label_LR_r3 = sentiment_mapping.get(prediction_LR_r3[0], \"unknown\")\n",
    "sent_label_LR_r4 = sentiment_mapping.get(prediction_LR_r4[0], \"unknown\")\n",
    "sent_label_LR_r5 = sentiment_mapping.get(prediction_LR_r5[0], \"unknown\")\n",
    "\n",
    " \n",
    "print(f\"Linear Regression: review \\\"{review1}\\\" is {sent_label_LR_r1}\")\n",
    "print(f\"Linear Regression: review \\\"{review2}\\\" is {sent_label_LR_r2}\")\n",
    "print(f\"Linear Regression: review \\\"{review3}\\\" is {sent_label_LR_r3}\")\n",
    "print(f\"Linear Regression: review \\\"{review4}\\\" is {sent_label_LR_r4}\")\n",
    "print(f\"Linear Regression: review \\\"{review5}\\\" is {sent_label_LR_r5}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
